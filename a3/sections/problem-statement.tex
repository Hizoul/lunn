\subsection{Problem Statement \& Motivation}
\label{sec:problem-statement}
% Warum machen wir das überhaupt?
Neural Networks with meaningful applications are complex structures with many layers, nodes and hence also trained parameters.
For example VGG19 consists of 19 Layers summing up to a total of 143,667,240 trained parameters\cite{vgg}. These parameters are trained to recognize images and map them to a description string.
The problem now is that there is no saying in what the individual layers or nodes have actually learned to respond to, or how the Neural Network actually draws a conclusion\cite{castelvecchi2016can}.
%  -> NN sind Blackboxes, haben zwar definierte Struktur, aber Zusammenspiel der Weights unbekannt
Such behaviour is often referred to as a \textit{black box} and one of the fundamental architectural problems in mastering neural networks\cite{olden2002illuminating}.

% besser nachvollziehen von klassifizierung durch besseres verständnis / visualisierung der gelernten merkmale
In order to get at least a small grasp of what these layers or nodes  techniques to visualize the learnt features have been developed.
This is of course limited to image processing neural networks and not generally applicable to look into any neural network.

\subsubsection{Visualizing Learned Features}

\subsubsection{Dreaming}

% https://research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html