\subsection{Problem Statement \& Motivation}
\label{sec:problem-statement}
% Warum machen wir das überhaupt?
Neural networks with meaningful applications are complex structures with many layers, nodes and trained weights.
For example VGG19 is an image categorization network that consists of 19 layers summing up to a total of 143,667,240 trainable parameters.\cite{vgg} Its weights are trained to recognize images and map them to a label based on the \textit{ImageNet} dataset.\cite{imagenet}

While this network is performing quite well, one problem is that there is no saying in what features the individual layers and nodes have learned to respond to and how the final conclusion is drawn.\cite{castelvecchi2016can}
This is one of the reasons that neural networks are often referred to as a \textit{black box} and is one of the fundamental architectural problems hindering quicker process in developing and mastering neural networks.\cite{olden2002illuminating}
Hence improving and training neural networks might be considered unscientific because it involves a process of trial and error where different model architectures and input data are evaluated.\cite{zeiler2014visualizing}
%  -> NN sind Blackboxes, haben zwar definierte Struktur, aber Zusammenspiel der Weights unbekannt


% besser nachvollziehen von klassifizierung durch besseres verständnis / visualisierung der gelernten merkmale
In order to get an idea of what these node weights and biases have learned, an approach to visualize said knowledge is needed.
The coming chapters are limited to convolutional neural networks and not generally applicable to \enquote{decipher} any neural network.