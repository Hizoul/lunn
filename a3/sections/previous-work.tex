\section{Related \& Previous Work}
\label{sec:previous-work}
\subsection{Previous Work}
There are different methods to visualize the learned features of a convolutional neural network.
As will be explained in section \ref{sec:how}, \textit{Deep Dream} uses the gradient ascent to achieve its results.
Before the use of the gradient ascent, Zeiler had already developed a method in 2011 called \emph{deconvolutional neural networks} to visualize said features.\cite{zeiler2011adaptive}

Simonyan has found that both approaches produce very similar results.
That is because from a mathematical standpoint the gradient ascent is a generalization of the deconvolutional approach.
This generalization also means that gradient ascent can be applied to any arbitrary layer while the deconvolutional neural network is limited to deciphering convolutional layers.\cite{simonyan2013deep}

\subsection{Related Work / Possible Applications}
The visualization of learned features can be used to achieve different artistic things.
Berov successfully applied \textit{Deep Dream} to imitate the visual effects a person might encounter during a hallucination onto any arbitrary image.\cite{berov2016visual}
We subjectively consider some of our results, visible in section \ref{sec:evaluation}, to also look quite \enquote{hallucinatory}.
DiPaola evalutated \textit{Deep Dream} as an alternative to style transfer.
This technique, also know as \emph{Deep Style}, is used to transform images in a manner that they look like they have been painted in a different style.\cite{dipaola2016using}
This process is called style transfer
DiPaola successfully transformed portrait pictures to look like they were painted by Rembrandt or Freud.
